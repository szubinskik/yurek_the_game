\documentclass[avery5371,grid,frame]{flashcards}

\usepackage{polski}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amssymb,mathtools}


\cardfrontstyle[\large\slshape]{headings}
\cardbackstyle{empty}


\begin{document}

\cardfrontfoot{Teoria Prawdopodobieństwa}


\begin{flashcard}[Twierdzenie]{Lematy Borela-Cantellego}

\smallskip
Niech $A_n$: ciąg zdarzeń losowych.
\begin{description}
\item[I lemat Borela-Cantellego] \hfill \\
	Jeśli $\sum P(A_n) < \infty$, to $P\left(\limsup{A_n}\right)=0$
\item[II lemat Borela-Cantellego] \hfill \\
	Jeśli $\sum P(A_n) = \infty$ i $A_n$ są stochastycznie niezależne, to $P\left(\limsup{A_n}\right)=1$ 
\end{description}
\end{flashcard}

\begin{flashcard}[Twierdzenie]{Twierdzenie Riesza}

\smallskip
Niech $X_n$: ciąg zmiennych losowych. \\ 
Jeśli $X_n \rightarrow X$ wg. $P$, to istnieją $n_k$ takie, \\
że $X_{n_k} \rightarrow X$ z $P1$.
\end{flashcard}

\begin{flashcard}[Definicja]{Ciasny (jędrny, tight) ciąg miar}

\smallskip
Ciąg miar jest ciasny, gdy
$$ (\forall \ \varepsilon > 0)(\exists \ a, b \in \mathbb{R})(\forall \ n > 0) \Big[\mu_n \left( (a,b] \right) > 1-\varepsilon \Big] $$
\end{flashcard}

\begin{flashcard}[Definicja]{$\pi$ i $\lambda$ systemy}

\smallskip
\begin{itemize}
\item Rodzina zbiorów $\mathcal{P}$ jest $\pi$-systemem, gdy jest \\
zamknięta na przekroje
\item Rodzina zbiorów $\mathcal{L}$ jest $\lambda$-systemem, gdy:
	\begin{enumerate}
	\item $\Omega \in \mathcal{L}$
	\item $A \subseteq B$ i $A, B \in \mathcal{L} \Rightarrow B \setminus A \in \mathcal{L}$
	\item $A_0 \subseteq A_1 \subseteq \ldots \in \mathcal{L} \Rightarrow \cup^{\infty}_{i=0} \ A_i \in \mathcal{L}$
	\end{enumerate}

\end{itemize}
\end{flashcard}


\begin{flashcard}[Twierdzenie]{Twierdzenie o $\pi$-$\lambda$-systemach (Dynkin)}

\smallskip
Niech $\mathcal{P}$: $\pi$-system, $\mathcal{L}$: $\lambda$-system \\
Jeśli $\mathcal{P} \subseteq \mathcal{L}$, to $\sigma(\mathcal{P}) \subseteq \mathcal{L}$
\end{flashcard}

\begin{flashcard}[Definicja]{Funkcja charakterystyczna}

\smallskip
Funkcję charakterystyczną zmiennej losowej $X \sim F$ określamy jako
{\begin{align*}
\varphi_X(t) = \mathbb{E} \left[ e^{itX} \right] &= \int_{\Omega} e^{itX} \ dP \\
             &= \int_{\mathbb{R}} e^{itx} \ d \mu \\
             &= \int_{-\infty}^{+\infty} e^{itx} \ dF_X 
\end{align*}}
\end{flashcard}

\begin{flashcard}[Twierdzenie]{Twierdzenie Lévy'ego o ciągłości}

\smallskip
\begin{enumerate}
\item Jeśli $\mu_n \Rightarrow \mu$ $(F_n \Rightarrow F)$, to \\ 
$(\forall \ t \in \mathbb{R})\left[\varphi_{\mu_n}(t) \rightarrow \varphi_\mu(t) \right]$
\item Jeśli $(\forall \ t \in \mathbb{R})\left[\varphi_{\mu_n}(t) \rightarrow \varphi(t) \right]$ i $\varphi(t)$ jest \\ ciągła w $0$, to $\varphi(t)$ jest ciągła na $\mathbb{R}$ i istnieje $\mu$ taka, że $\mu_n \Rightarrow \mu$
\end{enumerate}
\end{flashcard}

\begin{flashcard}[Twierdzenie]{Twierdzenie Skorochoda o reprezentacji}

\smallskip
Jeśli $F_n$, $F$: dystrybuanty i $F_n \Rightarrow F$, to istnieją $\left( \Omega, \mathcal{F}, P \right)$, $Y_n$, $Y$: zmienne losowe takie, że $F_{Y_n} = F_n$, $F_Y=F$ i $(\forall \ \omega \in \Omega)[Y_n(\omega) \rightarrow Y(\omega)]$
\end{flashcard}

\begin{flashcard}[Twierdzenie]{Różniczkowalność funkcji charakterystycznych}

\smallskip
Jeśli $\mathbb{E} \left[ |X|^k \right] < \infty$, to $\varphi_X$ jest $k$-krotnie różniczkowalna i $\varphi^{(k)}_X(0) = i^k \mathbb{E}[X^k]$
\end{flashcard}

\begin{flashcard}[Twierdzenie]{Prawo zero-jedynkowe Kołmogorowa}

\smallskip
Niech $\mathcal{F}_1$, $\mathcal{F}_2$, \dots będą niezależnymi $\sigma$-ciałami. \\
Niech $\mathcal{F}_{n, \infty} \coloneqq \sigma(\mathcal{F}_n, \mathcal{F}_{n+1}, \dots)$ i \\ niech $\mathcal{F}_\infty \coloneqq \bigcap \limits_{n=1}^\infty \mathcal{F}_{k, \infty}$. \\
Wtedy, jeżeli $A \in \mathcal{F}_\infty$, to $P(A) = 1$ lub $P(A) = 0$.
\end{flashcard}

\begin{flashcard}[Twierdzenie]{Twierdzenie o dwóch szeregach}

\smallskip
Niech $X_n$: ciąg niezależnych zmiennych losowych. \\
Jeżeli $\sum \mathbb{E}[X_n] < \infty$ i $\sum Var(X_n) < \infty$, to $\sum X_n$ jest zbieżny p.n.
\end{flashcard}

\begin{flashcard}[Twierdzenie]{Twierdzenie o trzech szeregach}

\smallskip
Niech $X_n$: ciąg niezależnych zmiennych losowych. Jeśli $\sum X_n$ jest zbieżny z $P1$, to dla każdego $c > 0$:
\begin{itemize}
	\item $\sum \mathbb{E}[X_n^c] < \infty$,
	\item $\sum Var(X_n^c) < \infty$,
	\item $\sum \mathbb{P}(|X_n| > c) < \infty$.
\end{itemize}
Spełnianie dla pewnego $c > 0$ jest warunkiem dostatecznym zbieżności $\sum X_n$ z $P1$.
\end{flashcard}

\begin{flashcard}[Definicja]{Rodzaje zbieżności zmiennych}

\smallskip
\begin{enumerate}
	\item Zbieżność prawie na pewno ($P1$): $X_n \xrightarrow{a.s} X$, gdy $P(\{\omega: X_n(\omega) \rightarrow X(\omega)\}) = 1$.
	\item Zbieżność wg prawdopodobieństwa: $X_n \xrightarrow{P} X$, gdy dla każdego $\varepsilon > 0$ mamy \\
	$\lim_{n \to \infty} P(\omega : |X_n(\omega) - X(\omega)| > \varepsilon) = 0$.
	\item Zbieżność wg rozkładu: $X_n \Rightarrow X$, gdy \\ 
	$F_n(x) \to F(x)$ dla każdego $x \in C_{F_X}$.
\end{enumerate}
\end{flashcard}

\begin{flashcard}[Twierdzenie]{Zależności między rodzajami zbieżności}

\smallskip
Zbieżność p.n. $\implies$ zbieżność wg $P$ $\implies$ zbieżność wg rozkładu.
\end{flashcard}

\end{document}
